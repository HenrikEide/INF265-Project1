{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from collections import Counter\n",
    "from utils import train, set_device, compute_accuracy\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Word embedding\n",
    "\n",
    "Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read txt file and tokenize\n",
    "def read_tokenize_txt(path):\n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        tokens = nltk.tokenize.word_tokenize(f.read())\n",
    "    return tokens\n",
    "\n",
    "# Read all txt files in a directory and tokenize\n",
    "def read_tokenize_dir(path):\n",
    "    tokens = []\n",
    "    for file in os.listdir(path):\n",
    "        tokens += read_tokenize_txt(path + file) # Should use os.path.join\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train_data = read_tokenize_dir('../data_train/')\n",
    "test_data = read_tokenize_dir('../data_test/')\n",
    "val_data = read_tokenize_dir('../data_val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in training data: 2,757,691\n",
      "Number of distinct tokens in training data: 60,424\n",
      "Size of vocabulary: 2,177\n",
      "Comments:\n",
      "A little more than 3% of the tokens are in the vocabulary with the threshold of 100 occurences. This seems resonable.\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "def get_freq_vocab(data, min_freq=100):\n",
    "    freq = Counter(data)\n",
    "    vocab = {w:f for (w,f) in freq.items() if freq[w] >= min_freq}\n",
    "    return freq, vocab\n",
    "\n",
    "print(f\"Number of tokens in training data: {len(train_data):,}\")\n",
    "freq, vocab = get_freq_vocab(train_data, min_freq=100)\n",
    "print(f\"Number of distinct tokens in training data: {len(freq):,}\")\n",
    "print(f\"Size of vocabulary: {len(vocab):,}\")\n",
    "print(\"Comments:\\nA little more than 3% of the tokens are in the vocabulary with the threshold of 100 occurences. This seems resonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "class My_MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=16, context_size=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim*context_size)\n",
    "        self.embedding.load_state_dict(self.embedding.state_dict())\n",
    "        self.fc1 = nn.Linear(emb_dim*context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this to work we need to convert the tokenized data into a format that the model can understand by creating a context/target dataset. The context is the sequence of words that surround the target word. The target word is the word we are trying to predict given context. We can then create a dataset that pairs the context window with the target word. The context window will be the input to the model, and the target word will be the target for the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, vocab, context_size=3):\n",
    "    \"\"\"Create a PyTorch dataset of context/target pairs from text\"\"\"\n",
    "    # Remove words that are not in the vocabulary\n",
    "    text = [w for w in text if w in vocab]\n",
    "\n",
    "    # Map each word to its index in the vocabulary\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    # Transform the text as a list of integers.\n",
    "    data = [word_to_ix[word] for word in text]\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(context_size, len(text) - context_size):\n",
    "        target = data[i]\n",
    "        context = data[i - context_size:i] + data[i + 1:i + context_size + 1]\n",
    "        contexts.append(context)\n",
    "        targets.append(target)\n",
    "            \n",
    "    # Convert context/target lists to PyTorch tensor\n",
    "    context_tensor = torch.tensor(contexts)\n",
    "    target_tensor = torch.tensor(targets)\n",
    "\n",
    "    # Create a PyTorch dataset out of these context / target pairs\n",
    "    return TensorDataset(context_tensor, target_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Model1 ------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (6) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Henrik Olsen Eide\\UibEmner\\INF265\\INF265-Projects\\project3\\sequence_models.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Train and save model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train(\u001b[39m30\u001b[39;49m, optimizer, model, loss_fn, data_train, \u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Compute accuracy on training and validation data sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henrik Olsen Eide\\UibEmner\\INF265\\INF265-Projects\\project3\\utils.py:33\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(n_epochs, optimizer, model, loss_fn, train_loader, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     31\u001b[0m outputs \u001b[39m=\u001b[39m model(contexts)\n\u001b[1;32m---> 33\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, targets)\n\u001b[0;32m     34\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     35\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (6) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "\n",
    "torch.manual_seed(265)\n",
    "# train_freq and train_vocab are already initialized in Part 2\n",
    "data_train = create_dataset(train_data, vocab)\n",
    "\n",
    "val_freq, val_vocab = get_freq_vocab(val_data)\n",
    "data_val = create_dataset(val_data, val_vocab)\n",
    "\n",
    "test_freq, test_vocab = get_freq_vocab(test_data)\n",
    "data_test = create_dataset(test_data, test_vocab)\n",
    "\n",
    "embedding = nn.Embedding(len(vocab), 16)\n",
    "models = [My_MLP(len(vocab)), My_MLP(len(vocab)), My_MLP(len(vocab)), My_MLP(len(vocab))]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(model_name := f\"\\n------ Model{i+1} ------\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # I got this far without using DataLoader, and now I am filled with nothing but regret and shame.\n",
    "    train(30, optimizer, model, loss_fn, data_train, \"cpu\")\n",
    "    torch.save(model.to(device=\"cpu\"), f\"models/{model_name}.pt\")\n",
    "\n",
    "    # Compute accuracy on training and validation data sets\n",
    "    print(f\"Training accuracy: {compute_accuracy(model, data_train, 'cpu'):.2f}%\")\n",
    "    print(f\"Validation accuracy: {compute_accuracy(model, data_val, 'cpu'):.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
