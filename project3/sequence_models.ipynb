{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from collections import Counter\n",
    "from utils import train, set_device, compute_accuracy\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Word embedding\n",
    "\n",
    "Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read txt file and tokenize\n",
    "def read_tokenize_txt(path):\n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        tokens = nltk.tokenize.word_tokenize(f.read())\n",
    "    return tokens\n",
    "\n",
    "# Read all txt files in a directory and tokenize\n",
    "def read_tokenize_dir(path):\n",
    "    tokens = []\n",
    "    for file in os.listdir(path):\n",
    "        tokens += read_tokenize_txt(path + file)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train_data = read_tokenize_dir('../data_train/')\n",
    "test_data = read_tokenize_dir('../data_test/')\n",
    "val_data = read_tokenize_dir('../data_val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in training data: 2,757,691\n",
      "Number of distinct tokens in training data: 60,424\n",
      "Size of vocabulary: 2,177\n",
      "Comments:\n",
      "A little more than 3% of the tokens are in the vocabulary with the threshold of 100 occurences. This seems resonable.\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "def get_freq_vocab(data, min_freq=100):\n",
    "    freq = Counter(data)\n",
    "    vocab = {w:f for (w,f) in freq.items() if freq[w] >= min_freq}\n",
    "    return freq, vocab\n",
    "\n",
    "print(f\"Number of tokens in training data: {len(train_data):,}\")\n",
    "freq, vocab = get_freq_vocab(train_data, min_freq=100)\n",
    "print(f\"Number of distinct tokens in training data: {len(freq):,}\")\n",
    "print(f\"Size of vocabulary: {len(vocab):,}\")\n",
    "print(\"Comments:\\nA little more than 3% of the tokens are in the vocabulary with the threshold of 100 occurences. This seems resonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "class My_MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=16, context_size=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.embedding.load_state_dict(self.embedding.state_dict())\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.fc1 = nn.Linear(emb_dim*context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = F.relu(self.fc1(torch.mean(out, dim=1)))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this to work we need to convert the tokenized data into a format that the model can understand by creating a context/target dataset. The context is the sequence of words that surround the target word. The target word is the word we are trying to predict given context. We can then create a dataset that pairs the context window with the target word. The context window will be the input to the model, and the target word will be the target for the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataset(data, vocab, context_size=3):\n",
    "#     \"\"\"Create context/target dataset from text data\"\"\"\n",
    "    \n",
    "#     # Initialize lists to store contexts and targets\n",
    "#     contexts = []\n",
    "#     targets = []\n",
    "    \n",
    "#     # Iterate over the data tensor, extracting context/target pairs\n",
    "#     for i in range(len(data) - context_size):\n",
    "#         context = data[i-context_size:i] + data[i+1:i+1+context_size]\n",
    "#         target = data[i]\n",
    "#         contexts.append(context)\n",
    "#         targets.append(target)\n",
    "    \n",
    "#     # Convert context/target lists to PyTorch tensor\n",
    "#     context_tensor = torch.stack(contexts)\n",
    "#     target_tensor = torch.tensor(targets)\n",
    "\n",
    "#     return TensorDataset(context_tensor, target_tensor)\n",
    "\n",
    "def create_dataset(text, vocab, context_size=3):\n",
    "    \"\"\"Create a PyTorch dataset of context/target pairs from text\"\"\"\n",
    "    # Remove words that are not in the vocabulary\n",
    "    text = [w for w in text if w in vocab]\n",
    "\n",
    "    # Map each word to its index in the vocabulary\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    # Transform the text as a list of integers.\n",
    "    data = [word_to_ix[word] for word in text]\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(context_size, len(text) - context_size):\n",
    "        target = data[i]\n",
    "        context = data[i - context_size:i] + data[i + 1:i + context_size + 1]\n",
    "        contexts.append(context)\n",
    "        targets.append(target)\n",
    "            \n",
    "    # Convert context/target lists to PyTorch tensor\n",
    "    context_tensor = torch.tensor(contexts)\n",
    "    target_tensor = torch.tensor(targets)\n",
    "\n",
    "    # Create a PyTorch dataset out of these context / target pairs\n",
    "    return TensorDataset(context_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Henrik Olsen Eide\\UibEmner\\INF265\\INF265-Projects\\project3\\sequence_models.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data_test \u001b[39m=\u001b[39m create_dataset(test_data, vocab)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\u001b[39mlen\u001b[39m(vocab), \u001b[39m16\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m models \u001b[39m=\u001b[39m [My_MLP(embedding), My_MLP(embedding), My_MLP(embedding), My_MLP(embedding)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, model \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(models):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(model_name \u001b[39m:=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m------ Model\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Henrik Olsen Eide\\UibEmner\\INF265\\INF265-Projects\\project3\\sequence_models.ipynb Cell 8\u001b[0m in \u001b[0;36mMy_MLP.__init__\u001b[1;34m(self, vocab_size, emb_dim, context_size)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, vocab_size, emb_dim\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, context_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mEmbedding(vocab_size, emb_dim)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mload_state_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mstate_dict())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Henrik%20Olsen%20Eide/UibEmner/INF265/INF265-Projects/project3/sequence_models.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mparameters():\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:139\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_grad_by_freq \u001b[39m=\u001b[39m scale_grad_by_freq\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m _weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_parameters()\n\u001b[0;32m    141\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "\n",
    "torch.manual_seed(265)\n",
    "data_train = create_dataset(train_data, vocab)\n",
    "data_val = create_dataset(val_data, vocab)\n",
    "data_test = create_dataset(test_data, vocab)\n",
    "\n",
    "embedding = nn.Embedding(len(vocab), 16)\n",
    "models = [My_MLP(embedding), My_MLP(embedding), My_MLP(embedding), My_MLP(embedding)]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(model_name := f\"\\n------ Model{i+1} ------\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train and save model\n",
    "    train(30, optimizer, model, loss_fn, data_train, \"cpu\")\n",
    "    torch.save(model.to(device=\"cpu\"), f\"models/{model_name}.pt\")\n",
    "\n",
    "    # Compute accuracy on training and validation data sets\n",
    "    print(f\"Training accuracy: {compute_accuracy(model, data_train, 'cpu'):.2f}%\")\n",
    "    print(f\"Validation accuracy: {compute_accuracy(model, data_val, 'cpu'):.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
